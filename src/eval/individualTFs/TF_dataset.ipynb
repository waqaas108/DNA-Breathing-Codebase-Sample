{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "# import CNN_LSTM_n\n",
    "# import TF_data_loader\n",
    "from torch.utils import data as D\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we make the panset, non-normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../data/Chipseq_data/seq_breathing_feat.pkl', 'rb') as f:\n",
    "    seq_feat = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_map = torch.load('../../../data/Chipseq_data/FeatMap.pt')\n",
    "feat_map = {v: k for k, v in feat_map.items()}\n",
    "group_index = torch.load('../../../data/Chipseq_data/group_index.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "panset = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition in seq_feat:\n",
    "    partition = seq_feat[partition]\n",
    "    for seq_id in partition:\n",
    "        panset[seq_id] = partition[seq_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_map = torch.load('TF_map.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF_sorter(panset, TF_map):\n",
    "    np.random.seed(108)\n",
    "    data_dict = {}\n",
    "\n",
    "    progress_bar = tqdm(TF_map, desc='Sorting TFs', unit='TF')\n",
    "\n",
    "    for TF_name in progress_bar:\n",
    "        pos_seqs = TF_map[TF_name]['positive']\n",
    "        neg_seqs = TF_map[TF_name]['negative']\n",
    "\n",
    "        # Select the appropriate sample size based on the number of negative sequences available\n",
    "        sample_size = min(len(neg_seqs), len(pos_seqs) * 5)\n",
    "        neg_indices = np.random.choice(len(neg_seqs), sample_size, replace=False)\n",
    "        neg_seqs_selected = [neg_seqs[i] for i in neg_indices]\n",
    "\n",
    "        data_dict[TF_name] = {}\n",
    "        data_dict[TF_name]['train'] = {}\n",
    "        data_dict[TF_name]['test'] = {}\n",
    "\n",
    "        # Populate train and test partitions for positive sequences\n",
    "        pos_train_count = int(len(pos_seqs) * 0.8)\n",
    "        pos_train_seqs = pos_seqs[:pos_train_count]\n",
    "        pos_test_seqs = pos_seqs[pos_train_count:]\n",
    "\n",
    "        for seq_id in pos_train_seqs:\n",
    "            data_dict[TF_name]['train'][seq_id] = panset[seq_id]\n",
    "            data_dict[TF_name]['train'][seq_id]['label'] = np.array([1])\n",
    "\n",
    "        for seq_id in pos_test_seqs:\n",
    "            data_dict[TF_name]['test'][seq_id] = panset[seq_id]\n",
    "            data_dict[TF_name]['test'][seq_id]['label'] = np.array([1])\n",
    "\n",
    "        # Populate train and test partitions for negative sequences\n",
    "        neg_train_count = int(len(neg_seqs_selected) * 0.8)\n",
    "        neg_train_seqs = neg_seqs_selected[:neg_train_count]\n",
    "        neg_test_seqs = neg_seqs_selected[neg_train_count:]\n",
    "\n",
    "        for seq_id in neg_train_seqs:\n",
    "            data_dict[TF_name]['train'][seq_id] = panset[seq_id]\n",
    "            data_dict[TF_name]['train'][seq_id]['label'] = np.array([0])\n",
    "\n",
    "        for seq_id in neg_test_seqs:\n",
    "            data_dict[TF_name]['test'][seq_id] = panset[seq_id]\n",
    "            data_dict[TF_name]['test'][seq_id]['label'] = np.array([0])\n",
    "            \n",
    "        progress_bar.set_description(f'Sorting TFs: {TF_name}')\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211c46c51bbd4b339f2d51476d2da1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sorting TFs:   0%|          | 0/64 [00:00<?, ?TF/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dict = TF_sorter(panset, TF_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TF_dataset.pickle', 'wb') as f:\n",
    "    pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TF_dataset.pickle', 'rb') as f:\n",
    "    data_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: HNF4A\n",
      "Partition: train, Count: 95164\n",
      "Partition: test, Count: 23792\n",
      "\n",
      "TF: JUND\n",
      "Partition: train, Count: 130051\n",
      "Partition: test, Count: 32513\n",
      "\n",
      "TF: NFYB\n",
      "Partition: train, Count: 110702\n",
      "Partition: test, Count: 27676\n",
      "\n",
      "TF: FOXA1\n",
      "Partition: train, Count: 407889\n",
      "Partition: test, Count: 101973\n",
      "\n",
      "TF: SP1\n",
      "Partition: train, Count: 100180\n",
      "Partition: test, Count: 25046\n",
      "\n",
      "TF: EBF1\n",
      "Partition: train, Count: 206342\n",
      "Partition: test, Count: 51586\n",
      "\n",
      "TF: TAF1\n",
      "Partition: train, Count: 200433\n",
      "Partition: test, Count: 50109\n",
      "\n",
      "TF: BCL3\n",
      "Partition: train, Count: 99724\n",
      "Partition: test, Count: 24932\n",
      "\n",
      "TF: CHD2\n",
      "Partition: train, Count: 140016\n",
      "Partition: test, Count: 35004\n",
      "\n",
      "TF: ELF1\n",
      "Partition: train, Count: 248779\n",
      "Partition: test, Count: 62195\n",
      "\n",
      "TF: POLR2A\n",
      "Partition: train, Count: 681249\n",
      "Partition: test, Count: 170313\n",
      "\n",
      "TF: BRCA1\n",
      "Partition: train, Count: 48086\n",
      "Partition: test, Count: 12022\n",
      "\n",
      "TF: ZNF143\n",
      "Partition: train, Count: 36945\n",
      "Partition: test, Count: 9237\n",
      "\n",
      "TF: BHLHE40\n",
      "Partition: train, Count: 88833\n",
      "Partition: test, Count: 22209\n",
      "\n",
      "TF: FOSL1\n",
      "Partition: train, Count: 46353\n",
      "Partition: test, Count: 11589\n",
      "\n",
      "TF: NR2F2\n",
      "Partition: train, Count: 122352\n",
      "Partition: test, Count: 30588\n",
      "\n",
      "TF: GABPA\n",
      "Partition: train, Count: 129494\n",
      "Partition: test, Count: 32374\n",
      "\n",
      "TF: THAP1\n",
      "Partition: train, Count: 18278\n",
      "Partition: test, Count: 4570\n",
      "\n",
      "TF: GATA3\n",
      "Partition: train, Count: 267528\n",
      "Partition: test, Count: 66882\n",
      "\n",
      "TF: BATF\n",
      "Partition: train, Count: 139982\n",
      "Partition: test, Count: 34996\n",
      "\n",
      "TF: BCLAF1\n",
      "Partition: train, Count: 74952\n",
      "Partition: test, Count: 18738\n",
      "\n",
      "TF: IRF4\n",
      "Partition: train, Count: 109723\n",
      "Partition: test, Count: 27431\n",
      "\n",
      "TF: RAD21\n",
      "Partition: train, Count: 423436\n",
      "Partition: test, Count: 105860\n",
      "\n",
      "TF: TCF7L2\n",
      "Partition: train, Count: 32596\n",
      "Partition: test, Count: 8150\n",
      "\n",
      "TF: REST\n",
      "Partition: train, Count: 142473\n",
      "Partition: test, Count: 35619\n",
      "\n",
      "TF: TBP\n",
      "Partition: train, Count: 135129\n",
      "Partition: test, Count: 33783\n",
      "\n",
      "TF: E2F6\n",
      "Partition: train, Count: 128476\n",
      "Partition: test, Count: 32120\n",
      "\n",
      "TF: RUNX3\n",
      "Partition: train, Count: 407582\n",
      "Partition: test, Count: 101896\n",
      "\n",
      "TF: SPI1\n",
      "Partition: train, Count: 335260\n",
      "Partition: test, Count: 83816\n",
      "\n",
      "TF: TAF7\n",
      "Partition: train, Count: 22608\n",
      "Partition: test, Count: 5652\n",
      "\n",
      "TF: USF2\n",
      "Partition: train, Count: 66657\n",
      "Partition: test, Count: 16665\n",
      "\n",
      "TF: SMC3\n",
      "Partition: train, Count: 184526\n",
      "Partition: test, Count: 46132\n",
      "\n",
      "TF: PBX3\n",
      "Partition: train, Count: 40329\n",
      "Partition: test, Count: 10083\n",
      "\n",
      "TF: POU2F2\n",
      "Partition: train, Count: 170443\n",
      "Partition: test, Count: 42611\n",
      "\n",
      "TF: BCL11A\n",
      "Partition: train, Count: 94281\n",
      "Partition: test, Count: 23571\n",
      "\n",
      "TF: EP300\n",
      "Partition: train, Count: 452697\n",
      "Partition: test, Count: 113175\n",
      "\n",
      "TF: ATF3\n",
      "Partition: train, Count: 6456\n",
      "Partition: test, Count: 1614\n",
      "\n",
      "TF: EGR1\n",
      "Partition: train, Count: 184852\n",
      "Partition: test, Count: 46214\n",
      "\n",
      "TF: ETS1\n",
      "Partition: train, Count: 76185\n",
      "Partition: test, Count: 19047\n",
      "\n",
      "TF: MAX\n",
      "Partition: train, Count: 349137\n",
      "Partition: test, Count: 87285\n",
      "\n",
      "TF: TRIM28\n",
      "Partition: train, Count: 100881\n",
      "Partition: test, Count: 25221\n",
      "\n",
      "TF: CEBPB\n",
      "Partition: train, Count: 550012\n",
      "Partition: test, Count: 137504\n",
      "\n",
      "TF: SIX5\n",
      "Partition: train, Count: 48892\n",
      "Partition: test, Count: 12224\n",
      "\n",
      "TF: TFAP2C\n",
      "Partition: train, Count: 231163\n",
      "Partition: test, Count: 57791\n",
      "\n",
      "TF: FOSL2\n",
      "Partition: train, Count: 115785\n",
      "Partition: test, Count: 28947\n",
      "\n",
      "TF: YY1\n",
      "Partition: train, Count: 419995\n",
      "Partition: test, Count: 104999\n",
      "\n",
      "TF: FOXA2\n",
      "Partition: train, Count: 206870\n",
      "Partition: test, Count: 51718\n",
      "\n",
      "TF: USF1\n",
      "Partition: train, Count: 216144\n",
      "Partition: test, Count: 54036\n",
      "\n",
      "TF: PML\n",
      "Partition: train, Count: 143865\n",
      "Partition: test, Count: 35967\n",
      "\n",
      "TF: CTCF\n",
      "Partition: train, Count: 709299\n",
      "Partition: test, Count: 177326\n",
      "\n",
      "TF: TEAD4\n",
      "Partition: train, Count: 294489\n",
      "Partition: test, Count: 73623\n",
      "\n",
      "TF: ZBTB33\n",
      "Partition: train, Count: 10603\n",
      "Partition: test, Count: 2651\n",
      "\n",
      "TF: MAFK\n",
      "Partition: train, Count: 244464\n",
      "Partition: test, Count: 61116\n",
      "\n",
      "TF: PAX5\n",
      "Partition: train, Count: 119121\n",
      "Partition: test, Count: 29781\n",
      "\n",
      "TF: STAT3\n",
      "Partition: train, Count: 98409\n",
      "Partition: test, Count: 24603\n",
      "\n",
      "TF: PRDM1\n",
      "Partition: train, Count: 25761\n",
      "Partition: test, Count: 6441\n",
      "\n",
      "TF: GATA2\n",
      "Partition: train, Count: 91934\n",
      "Partition: test, Count: 22984\n",
      "\n",
      "TF: ZBTB7A\n",
      "Partition: train, Count: 127848\n",
      "Partition: test, Count: 31962\n",
      "\n",
      "TF: TCF12\n",
      "Partition: train, Count: 96801\n",
      "Partition: test, Count: 24201\n",
      "\n",
      "TF: SRF\n",
      "Partition: train, Count: 60897\n",
      "Partition: test, Count: 15225\n",
      "\n",
      "TF: RFX5\n",
      "Partition: train, Count: 130128\n",
      "Partition: test, Count: 32532\n",
      "\n",
      "TF: MEF2A\n",
      "Partition: train, Count: 117216\n",
      "Partition: test, Count: 29304\n",
      "\n",
      "TF: SIN3AK20\n",
      "Partition: train, Count: 126403\n",
      "Partition: test, Count: 31601\n",
      "\n",
      "TF: STAT5A\n",
      "Partition: train, Count: 66600\n",
      "Partition: test, Count: 16650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for TF_name, partitions in data_dict.items():\n",
    "    print(f'TF: {TF_name}')\n",
    "    for partition, seq_ids in partitions.items():\n",
    "        print(f'Partition: {partition}, Count: {len(seq_ids)}')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
