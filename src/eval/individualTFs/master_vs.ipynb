{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "# import CNN_LSTM_n\n",
    "# import TF_data_loader\n",
    "from torch.utils import data as D\n",
    "import numpy as np\n",
    "from sklearn.metrics import PrecisionRecallDisplay, RocCurveDisplay\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we make the panset, non-normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../data/Chipseq_data/seq_breathing_feat.pkl', 'rb') as f:\n",
    "    seq_feat = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_map = torch.load('../../../data/Chipseq_data/FeatMap.pt')\n",
    "feat_map = {v: k for k, v in feat_map.items()}\n",
    "group_index = torch.load('../../../data/Chipseq_data/group_index.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "panset = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition in seq_feat:\n",
    "    partition = seq_feat[partition]\n",
    "    for seq_id in partition:\n",
    "        panset[seq_id] = partition[seq_id]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has given us the panset, and now we make the positive/negative sorter for each TF\n",
    "\n",
    "Be reminded that the structure for panset is:\n",
    "\n",
    "seq_id:feature:value,\n",
    "\n",
    "and we are gonna have to run some heavy analysis on the label, which is a feature, to determine what is negative and positive for each TF\n",
    "\n",
    "--\n",
    "\n",
    "First, what is a TF? and how can we explain it in terms of the values in labels?\n",
    "A: panset[seq_id]['label'][cell-line index]\n",
    "\n",
    "--\n",
    "\n",
    "The sorter will fill TF_map:\n",
    "take a TF_name and the indices, then\n",
    "take a seq from panset, look at the label, then\n",
    "if label == 1 for any of the TF_indices in this seq's label, add it to that TF's positive partition, else\n",
    "if label != 1 for all of the TF_indices in this seq's label, add it to that TF's negative partition\n",
    "\n",
    "TF_map's structure:\n",
    "\n",
    "TF:partition(positive, negative):seq_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_map = {}\n",
    "\n",
    "# Iterate over the TF names\n",
    "for TF_name in group_index:\n",
    "    # Create a dictionary for the TF name\n",
    "    TF_dict = {}\n",
    "    \n",
    "    # Iterate over the partitions (positive and negative)\n",
    "    for partition in ['positive', 'negative']:\n",
    "        # Initialize an empty list for the partition\n",
    "        TF_dict[partition] = []\n",
    "    \n",
    "    # Add the TF dictionary to the layered dictionary\n",
    "    TF_map[TF_name] = TF_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026c5dc50eb6474a88489e695e2401e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing sequences:   0%|          | 0/886625 [00:00<?, ?sequence/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for seq_id in tqdm(panset, desc='Processing sequences', unit='sequence'):\n",
    "    seq_data = panset[seq_id]\n",
    "    for index, label_value in enumerate(seq_data['label']):\n",
    "        # Check if the label is 1 for any TF_indices in this seq's label\n",
    "        if label_value == 1:\n",
    "            for TF_name, label_indices in group_index.items():\n",
    "                if index in label_indices:\n",
    "                    # Add the seq_id to the positive partition of the TF\n",
    "                    TF_map[TF_name]['positive'].append(seq_id)\n",
    "                    break\n",
    "        else:\n",
    "            # If the label is not 1 for all TF_indices, add the seq_id to the negative partition of the respective TFs\n",
    "            for TF_name, label_indices in group_index.items():\n",
    "                if all(label_value != 1 for label_index in label_indices):\n",
    "                    TF_map[TF_name]['negative'].append(seq_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for TF_name, partitions in TF_map.items():\n",
    "    print(f'TF: {TF_name}')\n",
    "    for partition, seq_ids in partitions.items():\n",
    "        print(f'Partition: {partition}, Count: {len(seq_ids)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(TF_map, 'TF_map.pt')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This hopefully has given us the mapped dataset, now we need to write something that uses panset and TF_map to create the set that goes into the ML model.\n",
    "\n",
    "Let's figure out the ML chain here:\n",
    "\n",
    "1. Tell trainer the Model file, probably one of the kernel variations of the CNN_LSTM,\n",
    "2. Give trainer TF_list to iterate over,\n",
    "3. Trainer picks out a TF's mapping and applies it to panset somehow\n",
    "    a. now we have the positive and negative sets, we incorporate this as the new label, remove the old one\n",
    "    b. specify a random seed and keep positive to negative at a 1:10 ratio\n",
    "    c. specify a random seed and then shuffle into test and train\n",
    "    d. normalize train, then use the mean/sd of train to normalise test\n",
    "    e. save the TF_name: mean/sd somewhere\n",
    "    \n",
    "Now we have a dataset, and the trainer should give this to the model\n",
    "\n",
    "The trainer will do this for every TF, and then save an ML checkpoint named after the TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data as D\n",
    "import pickle\n",
    "\n",
    "# so this is a necessary preprocessing step right\n",
    "def seq2onehot(seq):\n",
    "    window_size = 500\n",
    "    matrix = np.zeros(shape = (4, window_size), dtype = np.uint8)\n",
    "    for i, nt in enumerate(seq):\n",
    "        if nt == \"A\":\n",
    "            matrix[0][i] = 1\n",
    "        elif nt == \"G\":\n",
    "            matrix[1][i] = 1\n",
    "        elif nt == \"C\":\n",
    "            matrix[2][i] = 1\n",
    "        elif nt == \"T\":\n",
    "            matrix[3][i] = 1\n",
    "        else:\n",
    "            continue\n",
    "    return matrix\n",
    "\n",
    "def TF_sorter(panset, TF_map):\n",
    "    np.random.seed(108)\n",
    "    data_dict = {}\n",
    "\n",
    "    for TF_name in TF_map:\n",
    "        pos_seqs = TF_name['positive']\n",
    "        neg_seqs = TF_name['negative']\n",
    "\n",
    "        # Select 10 times the number of positive sequences from the negative sequences\n",
    "        neg_indices = np.random.choice(len(neg_seqs), len(pos_seqs) * 10, replace=False)\n",
    "        neg_seqs_selected = [neg_seqs[i] for i in neg_indices]\n",
    "\n",
    "        data_dict[TF_name] = {}\n",
    "        data_dict[TF_name]['train'] = {}\n",
    "        data_dict[TF_name]['test'] = {}\n",
    "\n",
    "        # Populate train and test partitions for positive sequences\n",
    "        pos_train_count = int(len(pos_seqs) * 0.8)\n",
    "        pos_train_seqs = pos_seqs[:pos_train_count]\n",
    "        pos_test_seqs = pos_seqs[pos_train_count:]\n",
    "\n",
    "        for seq_id in pos_train_seqs:\n",
    "            data_dict[TF_name]['train'][seq_id] = panset[seq_id]\n",
    "            data_dict[TF_name]['train'][seq_id]['label'] = np.array([1])\n",
    "\n",
    "        for seq_id in pos_test_seqs:\n",
    "            data_dict[TF_name]['test'][seq_id] = panset[seq_id]\n",
    "            data_dict[TF_name]['test'][seq_id]['label'] = np.array([1])\n",
    "\n",
    "        # Populate train and test partitions for negative sequences\n",
    "        neg_train_count = int(len(neg_seqs_selected) * 0.8)\n",
    "        neg_train_seqs = neg_seqs_selected[:neg_train_count]\n",
    "        neg_test_seqs = neg_seqs_selected[neg_train_count:]\n",
    "\n",
    "        for seq_id in neg_train_seqs:\n",
    "            data_dict[TF_name]['train'][seq_id] = panset[seq_id]\n",
    "            data_dict[TF_name]['train'][seq_id]['label'] = np.array([0])\n",
    "\n",
    "        for seq_id in neg_test_seqs:\n",
    "            data_dict[TF_name]['test'][seq_id] = panset[seq_id]\n",
    "            data_dict[TF_name]['test'][seq_id]['label'] = np.array([0])\n",
    "\n",
    "        del data_dict[TF_name]['positive']\n",
    "        del data_dict[TF_name]['negative']\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# and this is the dataloader proper\n",
    "class TF_data(D.Dataset):\n",
    "    def __init__(self, panset_path, TF_map_path, TF):\n",
    "        self.data_dict = TF_sorter(panset_path, TF_map_path)[TF]\n",
    "        self.id_list = list(self.data_dict)\n",
    "        self.len = len(self.id_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        seq_id = self.id_list[index]\n",
    "        sample = self.data_dict[seq_id]\n",
    "        seq = torch.from_numpy(seq2onehot(sample['seq'])).float()\n",
    "        label = torch.from_numpy(sample['label']).float()\n",
    "        coord_feat = torch.from_numpy(sample['coord'])\n",
    "        coordsq_feat = torch.from_numpy(sample['coord_sq'])\n",
    "        flip_feat = torch.from_numpy(sample['flip'])\n",
    "        bio_feat = torch.stack([coord_feat, coordsq_feat, flip_feat], dim = 0).float()\n",
    "        #bio_feat = torch.cat([seq, bio_feat], dim = 0).float()\n",
    "        return seq, bio_feat, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Dset = TF_data(data_path='/home/blai/Breathing/data/Chipseq_data/seq_breathing_feat.pkl', partition = 'train')\n",
    "    for feat in Dset:\n",
    "        print(feat[0].size())\n",
    "        print(feat[1].size())\n",
    "        print(feat[2].size())      \n",
    "\n",
    "         \n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
