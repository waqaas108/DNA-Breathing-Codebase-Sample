{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "# import CNN_LSTM_n\n",
    "# import TF_data_loader\n",
    "from torch.utils import data as D\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer(dataset):\n",
    "    stat_summary = {}\n",
    "    train_data = dataset['train']\n",
    "\n",
    "    for feature in ['coord', 'coord_sq', 'flip']:\n",
    "        train_values = np.concatenate([seq[feature] for seq in train_data.values()])\n",
    "\n",
    "        mean = np.mean(train_values)\n",
    "        std = np.std(train_values, ddof=0)\n",
    "\n",
    "        for partition in dataset:\n",
    "                current_partition = dataset[partition]\n",
    "                for seq in current_partition:\n",
    "                    data = current_partition[seq]\n",
    "                    data[feature] = (data[feature] - mean)/std\n",
    "                    dataset[partition][seq][feature] = data[feature]\n",
    "\n",
    "        stat_summary[feature] = {'mean': mean, 'std': std}\n",
    "        \n",
    "    return dataset, stat_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_checker(dataset):\n",
    "    stat_summary = {}\n",
    "    train_data = dataset['train']\n",
    "\n",
    "    for feature in ['coord', 'coord_sq', 'flip']:\n",
    "        train_values = np.concatenate([seq[feature] for seq in train_data.values()])\n",
    "\n",
    "        mean = np.mean(train_values)\n",
    "        std = np.std(train_values, ddof=0)\n",
    "        stat_summary[feature] = {'mean': mean, 'std': std}\n",
    "        \n",
    "    return stat_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFs = os.listdir('TF_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GABPA.pkl\n",
    "with open('TF_datasets/GABPA.pkl', 'rb') as f:\n",
    "    GABPA = pickle.load(f)\n",
    "normal_GABPA, GABPA_stat = normalizer(GABPA)\n",
    "normal_GABPA_stat = stat_checker(normal_GABPA)\n",
    "with open('normal_datasets/GABPA.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_GABPA, f)\n",
    "print('GABPA:', GABPA_stat)\n",
    "print('Normalized GABPA:', normal_GABPA_stat)\n",
    "\n",
    "# PML.pkl\n",
    "with open('TF_datasets/PML.pkl', 'rb') as f:\n",
    "    PML = pickle.load(f)\n",
    "normal_PML, PML_stat = normalizer(PML)\n",
    "normal_PML_stat = stat_checker(normal_PML)\n",
    "with open('normal_datasets/PML.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_PML, f)\n",
    "print('PML:', PML_stat)\n",
    "print('Normalized PML:', normal_PML_stat)\n",
    "\n",
    "# POU2F2.pkl\n",
    "with open('TF_datasets/POU2F2.pkl', 'rb') as f:\n",
    "    POU2F2 = pickle.load(f)\n",
    "normal_POU2F2, POU2F2_stat = normalizer(POU2F2)\n",
    "normal_POU2F2_stat = stat_checker(normal_POU2F2)\n",
    "with open('normal_datasets/POU2F2.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_POU2F2, f)\n",
    "print('POU2F2:', POU2F2_stat)\n",
    "print('Normalized POU2F2:', normal_POU2F2_stat)\n",
    "\n",
    "# USF1.pkl\n",
    "with open('TF_datasets/USF1.pkl', 'rb') as f:\n",
    "    USF1 = pickle.load(f)\n",
    "normal_USF1, USF1_stat = normalizer(USF1)\n",
    "normal_USF1_stat = stat_checker(normal_USF1)\n",
    "with open('normal_datasets/USF1.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_USF1, f)\n",
    "print('USF1:', USF1_stat)\n",
    "print('Normalized USF1:', normal_USF1_stat)\n",
    "\n",
    "# EGR1.pkl\n",
    "with open('TF_datasets/EGR1.pkl', 'rb') as f:\n",
    "    EGR1 = pickle.load(f)\n",
    "normal_EGR1, EGR1_stat = normalizer(EGR1)\n",
    "normal_EGR1_stat = stat_checker(normal_EGR1)\n",
    "with open('normal_datasets/EGR1.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_EGR1, f)\n",
    "print('EGR1:', EGR1_stat)\n",
    "print('Normalized EGR1:', normal_EGR1_stat)\n",
    "\n",
    "# TAF1.pkl\n",
    "with open('TF_datasets/TAF1.pkl', 'rb') as f:\n",
    "    TAF1 = pickle.load(f)\n",
    "normal_TAF1, TAF1_stat = normalizer(TAF1)\n",
    "normal_TAF1_stat = stat_checker(normal_TAF1)\n",
    "with open('normal_datasets/TAF1.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_TAF1, f)\n",
    "print('TAF1:', TAF1_stat)\n",
    "print('Normalized TAF1:', normal_TAF1_stat)\n",
    "\n",
    "# BCLAF1.pkl\n",
    "with open('TF_datasets/BCLAF1.pkl', 'rb') as f:\n",
    "    BCLAF1 = pickle.load(f)\n",
    "normal_BCLAF1, BCLAF1_stat = normalizer(BCLAF1)\n",
    "normal_BCLAF1_stat = stat_checker(normal_BCLAF1)\n",
    "with open('normal_datasets/BCLAF1.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_BCLAF1, f)\n",
    "print('BCLAF1:', BCLAF1_stat)\n",
    "print('Normalized BCLAF1:', normal_BCLAF1_stat)\n",
    "\n",
    "# THAP1.pkl\n",
    "with open('TF_datasets/THAP1.pkl', 'rb') as f:\n",
    "    THAP1 = pickle.load(f)\n",
    "normal_THAP1, THAP1_stat = normalizer(THAP1)\n",
    "normal_THAP1_stat = stat_checker(normal_THAP1)\n",
    "with open('normal_datasets/THAP1.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_THAP1, f)\n",
    "print('THAP1:', THAP1_stat)\n",
    "print('Normalized THAP1:', normal_THAP1_stat)\n",
    "\n",
    "# CHD2.pkl\n",
    "with open('TF_datasets/CHD2.pkl', 'rb') as f:\n",
    "    CHD2 = pickle.load(f)\n",
    "normal_CHD2, CHD2_stat = normalizer(CHD2)\n",
    "normal_CHD2_stat = stat_checker(normal_CHD2)\n",
    "with open('normal_datasets/CHD2.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_CHD2, f)\n",
    "print('CHD2:', CHD2_stat)\n",
    "print('Normalized CHD2:', normal_CHD2_stat)\n",
    "\n",
    "# BCL11A.pkl\n",
    "with open('TF_datasets/BCL11A.pkl', 'rb') as f:\n",
    "    BCL11A = pickle.load(f)\n",
    "normal_BCL11A, BCL11A_stat = normalizer(BCL11A)\n",
    "normal_BCL11A_stat = stat_checker(normal_BCL11A)\n",
    "with open('normal_datasets/BCL11A.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_BCL11A, f)\n",
    "print('BCL11A:', BCL11A_stat)\n",
    "print('Normalized BCL11A:', normal_BCL11A_stat)\n",
    "\n",
    "# EP300.pkl\n",
    "with open('TF_datasets/EP300.pkl', 'rb') as f:\n",
    "    EP300 = pickle.load(f)\n",
    "normal_EP300, EP300_stat = normalizer(EP300)\n",
    "normal_EP300_stat = stat_checker(normal_EP300)\n",
    "with open('normal_datasets/EP300.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_EP300, f)\n",
    "print('EP300:', EP300_stat)\n",
    "print('Normalized EP300:', normal_EP300_stat)\n",
    "\n",
    "# JUND.pkl\n",
    "with open('TF_datasets/JUND.pkl', 'rb') as f:\n",
    "    JUND = pickle.load(f)\n",
    "normal_JUND, JUND_stat = normalizer(JUND)\n",
    "normal_JUND_stat = stat_checker(normal_JUND)\n",
    "with open('normal_datasets/JUND.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_JUND, f)\n",
    "print('JUND:', JUND_stat)\n",
    "print('Normalized JUND:', normal_JUND_stat)\n",
    "\n",
    "# RUNX3.pkl\n",
    "with open('TF_datasets/RUNX3.pkl', 'rb') as f:\n",
    "    RUNX3 = pickle.load(f)\n",
    "normal_RUNX3, RUNX3_stat = normalizer(RUNX3)\n",
    "normal_RUNX3_stat = stat_checker(normal_RUNX3)\n",
    "with open('normal_datasets/RUNX3.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_RUNX3, f)\n",
    "print('RUNX3:', RUNX3_stat)\n",
    "print('Normalized RUNX3:', normal_RUNX3_stat)\n",
    "\n",
    "# GATA2.pkl\n",
    "with open('TF_datasets/GATA2.pkl', 'rb') as f:\n",
    "    GATA2 = pickle.load(f)\n",
    "normal_GATA2, GATA2_stat = normalizer(GATA2)\n",
    "normal_GATA2_stat = stat_checker(normal_GATA2)\n",
    "with open('normal_datasets/GATA2.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_GATA2, f)\n",
    "print('GATA2:', GATA2_stat)\n",
    "print('Normalized GATA2:', normal_GATA2_stat)\n",
    "\n",
    "# ELF1.pkl\n",
    "with open('TF_datasets/ELF1.pkl', 'rb') as f:\n",
    "    ELF1 = pickle.load(f)\n",
    "normal_ELF1, ELF1_stat = normalizer(ELF1)\n",
    "normal_ELF1_stat = stat_checker(normal_ELF1)\n",
    "with open('normal_datasets/ELF1.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_ELF1, f)\n",
    "print('ELF1:', ELF1_stat)\n",
    "print('Normalized ELF1:', normal_ELF1_stat)\n",
    "\n",
    "# RFX5.pkl\n",
    "with open('TF_datasets/RFX5.pkl', 'rb') as f:\n",
    "    RFX5 = pickle.load(f)\n",
    "normal_RFX5, RFX5_stat = normalizer(RFX5)\n",
    "normal_RFX5_stat = stat_checker(normal_RFX5)\n",
    "with open('normal_datasets/RFX5.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_RFX5, f)\n",
    "print('RFX5:', RFX5_stat)\n",
    "print('Normalized RFX5:', normal_RFX5_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFAP2C.pkl\n",
    "with open('TF_datasets/TFAP2C.pkl', 'rb') as f:\n",
    "    TFAP2C = pickle.load(f)\n",
    "normal_TFAP2C, TFAP2C_stat = normalizer(TFAP2C)\n",
    "normal_TFAP2C_stat = stat_checker(normal_TFAP2C)\n",
    "with open('normal_datasets/TFAP2C.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_TFAP2C, f)\n",
    "print('TFAP2C:', TFAP2C_stat)\n",
    "print('Normalized TFAP2C:', normal_TFAP2C_stat)\n",
    "\n",
    "# CTCF.pkl\n",
    "with open('TF_datasets/CTCF.pkl', 'rb') as f:\n",
    "    CTCF = pickle.load(f)\n",
    "normal_CTCF, CTCF_stat = normalizer(CTCF)\n",
    "normal_CTCF_stat = stat_checker(normal_CTCF)\n",
    "with open('normal_datasets/CTCF.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_CTCF, f)\n",
    "print('CTCF:', CTCF_stat)\n",
    "print('Normalized CTCF:', normal_CTCF_stat)\n",
    "\n",
    "# ETS1.pkl\n",
    "with open('TF_datasets/ETS1.pkl', 'rb') as f:\n",
    "    ETS1 = pickle.load(f)\n",
    "normal_ETS1, ETS1_stat = normalizer(ETS1)\n",
    "normal_ETS1_stat = stat_checker(normal_ETS1)\n",
    "with open('normal_datasets/ETS1.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_ETS1, f)\n",
    "print('ETS1:', ETS1_stat)\n",
    "print('Normalized ETS1:', normal_ETS1_stat)\n",
    "\n",
    "# PAX5.pkl\n",
    "with open('TF_datasets/PAX5.pkl', 'rb') as f:\n",
    "    PAX5 = pickle.load(f)\n",
    "normal_PAX5, PAX5_stat = normalizer(PAX5)\n",
    "normal_PAX5_stat = stat_checker(normal_PAX5)\n",
    "with open('normal_datasets/PAX5.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_PAX5, f)\n",
    "print('PAX5:', PAX5_stat)\n",
    "print('Normalized PAX5:', normal_PAX5_stat)\n",
    "\n",
    "# REST.pkl\n",
    "with open('TF_datasets/REST.pkl', 'rb') as f:\n",
    "    REST = pickle.load(f)\n",
    "normal_REST, REST_stat = normalizer(REST)\n",
    "normal_REST_stat = stat_checker(normal_REST)\n",
    "with open('normal_datasets/REST.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_REST, f)\n",
    "print('REST:', REST_stat)\n",
    "print('Normalized REST:', normal_REST_stat)\n",
    "\n",
    "# ZNF143.pkl\n",
    "with open('TF_datasets/ZNF143.pkl', 'rb') as f:\n",
    "    ZNF143 = pickle.load(f)\n",
    "normal_ZNF143, ZNF143_stat = normalizer(ZNF143)\n",
    "normal_ZNF143_stat = stat_checker(normal_ZNF143)\n",
    "with open('normal_datasets/ZNF143.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_ZNF143, f)\n",
    "print('ZNF143:', ZNF143_stat)\n",
    "print('Normalized ZNF143:', normal_ZNF143_stat)\n",
    "\n",
    "# BATF.pkl\n",
    "with open('TF_datasets/BATF.pkl', 'rb') as f:\n",
    "    BATF = pickle.load(f)\n",
    "normal_BATF, BATF_stat = normalizer(BATF)\n",
    "normal_BATF_stat = stat_checker(normal_BATF)\n",
    "with open('normal_datasets/BATF.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_BATF, f)\n",
    "print('BATF:', BATF_stat)\n",
    "print('Normalized BATF:', normal_BATF_stat)\n",
    "\n",
    "# PBX3.pkl\n",
    "with open('TF_datasets/PBX3.pkl', 'rb') as f:\n",
    "    PBX3 = pickle.load(f)\n",
    "normal_PBX3, PBX3_stat = normalizer(PBX3)\n",
    "normal_PBX3_stat = stat_checker(normal_PBX3)\n",
    "with open('normal_datasets/PBX3.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_PBX3, f)\n",
    "print('PBX3:', PBX3_stat)\n",
    "print('Normalized PBX3:', normal_PBX3_stat)\n",
    "\n",
    "# USF2.pkl\n",
    "with open('TF_datasets/USF2.pkl', 'rb') as f:\n",
    "    USF2 = pickle.load(f)\n",
    "normal_USF2, USF2_stat = normalizer(USF2)\n",
    "normal_USF2_stat = stat_checker(normal_USF2)\n",
    "with open('normal_datasets/USF2.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_USF2, f)\n",
    "print('USF2:', USF2_stat)\n",
    "print('Normalized USF2:', normal_USF2_stat)\n",
    "\n",
    "# SIX5.pkl\n",
    "with open('TF_datasets/SIX5.pkl', 'rb') as f:\n",
    "    SIX5 = pickle.load(f)\n",
    "normal_SIX5, SIX5_stat = normalizer(SIX5)\n",
    "normal_SIX5_stat = stat_checker(normal_SIX5)\n",
    "with open('normal_datasets/SIX5.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_SIX5, f)\n",
    "print('SIX5:', SIX5_stat)\n",
    "print('Normalized SIX5:', normal_SIX5_stat)\n",
    "\n",
    "# IRF4.pkl\n",
    "with open('TF_datasets/IRF4.pkl', 'rb') as f:\n",
    "    IRF4 = pickle.load(f)\n",
    "normal_IRF4, IRF4_stat = normalizer(IRF4)\n",
    "normal_IRF4_stat = stat_checker(normal_IRF4)\n",
    "with open('normal_datasets/IRF4.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_IRF4, f)\n",
    "print('IRF4:', IRF4_stat)\n",
    "print('Normalized IRF4:', normal_IRF4_stat)\n",
    "\n",
    "# TCF7L2.pkl\n",
    "with open('TF_datasets/TCF7L2.pkl', 'rb') as f:\n",
    "    TCF7L2 = pickle.load(f)\n",
    "normal_TCF7L2, TCF7L2_stat = normalizer(TCF7L2)\n",
    "normal_TCF7L2_stat = stat_checker(normal_TCF7L2)\n",
    "with open('normal_datasets/TCF7L2.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_TCF7L2, f)\n",
    "print('TCF7L2:', TCF7L2_stat)\n",
    "print('Normalized TCF7L2:', normal_TCF7L2_stat)\n",
    "\n",
    "# SIN3AK20.pkl\n",
    "with open('TF_datasets/SIN3AK20.pkl', 'rb') as f:\n",
    "    SIN3AK20 = pickle.load(f)\n",
    "normal_SIN3AK20, SIN3AK20_stat = normalizer(SIN3AK20)\n",
    "normal_SIN3AK20_stat = stat_checker(normal_SIN3AK20)\n",
    "with open('normal_datasets/SIN3AK20.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_SIN3AK20, f)\n",
    "print('SIN3AK20:', SIN3AK20_stat)\n",
    "print('Normalized SIN3AK20:', normal_SIN3AK20_stat)\n",
    "\n",
    "# SPI1.pkl\n",
    "with open('TF_datasets/SPI1.pkl', 'rb') as f:\n",
    "    SPI1 = pickle.load(f)\n",
    "normal_SPI1, SPI1_stat = normalizer(SPI1)\n",
    "normal_SPI1_stat = stat_checker(normal_SPI1)\n",
    "with open('normal_datasets/SPI1.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_SPI1, f)\n",
    "print('SPI1:', SPI1_stat)\n",
    "print('Normalized SPI1:', normal_SPI1_stat)\n",
    "\n",
    "# E2F6.pkl\n",
    "with open('TF_datasets/E2F6.pkl', 'rb') as f:\n",
    "    E2F6 = pickle.load(f)\n",
    "normal_E2F6, E2F6_stat = normalizer(E2F6)\n",
    "normal_E2F6_stat = stat_checker(normal_E2F6)\n",
    "with open('normal_datasets/E2F6.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_E2F6, f)\n",
    "print('E2F6:', E2F6_stat)\n",
    "print('Normalized E2F6:', normal_E2F6_stat)\n",
    "\n",
    "# FOSL2.pkl\n",
    "with open('TF_datasets/FOSL2.pkl', 'rb') as f:\n",
    "    FOSL2 = pickle.load(f)\n",
    "normal_FOSL2, FOSL2_stat = normalizer(FOSL2)\n",
    "normal_FOSL2_stat = stat_checker(normal_FOSL2)\n",
    "with open('normal_datasets/FOSL2.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_FOSL2, f)\n",
    "print('FOSL2:', FOSL2_stat)\n",
    "print('Normalized FOSL2:', normal_FOSL2_stat)\n",
    "\n",
    "# ZBTB33.pkl\n",
    "with open('TF_datasets/ZBTB33.pkl', 'rb') as f:\n",
    "    ZBTB33 = pickle.load(f)\n",
    "normal_ZBTB33, ZBTB33_stat = normalizer(ZBTB33)\n",
    "normal_ZBTB33_stat = stat_checker(normal_ZBTB33)\n",
    "with open('normal_datasets/ZBTB33.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_ZBTB33, f)\n",
    "print('ZBTB33:', ZBTB33_stat)\n",
    "print('Normalized ZBTB33:', normal_ZBTB33_stat)\n",
    "\n",
    "# STAT3.pkl\n",
    "with open('TF_datasets/STAT3.pkl', 'rb') as f:\n",
    "    STAT3 = pickle.load(f)\n",
    "normal_STAT3, STAT3_stat = normalizer(STAT3)\n",
    "normal_STAT3_stat = stat_checker(normal_STAT3)\n",
    "with open('normal_datasets/STAT3.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_STAT3, f)\n",
    "print('STAT3:', STAT3_stat)\n",
    "print('Normalized STAT3:', normal_STAT3_stat)\n",
    "\n",
    "# SP1.pkl\n",
    "with open('TF_datasets/SP1.pkl', 'rb') as f:\n",
    "    SP1 = pickle.load(f)\n",
    "normal_SP1, SP1_stat = normalizer(SP1)\n",
    "normal_SP1_stat = stat_checker(normal_SP1)\n",
    "with open('normal_datasets/SP1.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_SP1, f)\n",
    "print('SP1:', SP1_stat)\n",
    "print('Normalized SP1:', normal_SP1_stat)\n",
    "\n",
    "# TRIM28.pkl\n",
    "with open('TF_datasets/TRIM28.pkl', 'rb') as f:\n",
    "    TRIM28 = pickle.load(f)\n",
    "normal_TRIM28, TRIM28_stat = normalizer(TRIM28)\n",
    "normal_TRIM28_stat = stat_checker(normal_TRIM28)\n",
    "with open('normal_datasets/TRIM28.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_TRIM28, f)\n",
    "print('TRIM28:', TRIM28_stat)\n",
    "print('Normalized TRIM28:', normal_TRIM28_stat)\n",
    "\n",
    "# FOXA2.pkl\n",
    "with open('TF_datasets/FOXA2.pkl', 'rb') as f:\n",
    "    FOXA2 = pickle.load(f)\n",
    "normal_FOXA2, FOXA2_stat = normalizer(FOXA2)\n",
    "normal_FOXA2_stat = stat_checker(normal_FOXA2)\n",
    "with open('normal_datasets/FOXA2.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_FOXA2, f)\n",
    "print('FOXA2:', FOXA2_stat)\n",
    "print('Normalized FOXA2:', normal_FOXA2_stat)\n",
    "\n",
    "# ZBTB7A.pkl\n",
    "with open('TF_datasets/ZBTB7A.pkl', 'rb') as f:\n",
    "    ZBTB7A = pickle.load(f)\n",
    "normal_ZBTB7A, ZBTB7A_stat = normalizer(ZBTB7A)\n",
    "normal_ZBTB7A_stat = stat_checker(normal_ZBTB7A)\n",
    "with open('normal_datasets/ZBTB7A.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_ZBTB7A, f)\n",
    "print('ZBTB7A:', ZBTB7A_stat)\n",
    "print('Normalized ZBTB7A:', normal_ZBTB7A_stat)\n",
    "\n",
    "# SRF.pkl\n",
    "with open('TF_datasets/SRF.pkl', 'rb') as f:\n",
    "    SRF = pickle.load(f)\n",
    "normal_SRF, SRF_stat = normalizer(SRF)\n",
    "normal_SRF_stat = stat_checker(normal_SRF)\n",
    "with open('normal_datasets/SRF.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_SRF, f)\n",
    "print('SRF:', SRF_stat)\n",
    "print('Normalized SRF:', normal_SRF_stat)\n",
    "\n",
    "# NFYB.pkl\n",
    "with open('TF_datasets/NFYB.pkl', 'rb') as f:\n",
    "    NFYB = pickle.load(f)\n",
    "normal_NFYB, NFYB_stat = normalizer(NFYB)\n",
    "normal_NFYB_stat = stat_checker(normal_NFYB)\n",
    "with open('normal_datasets/NFYB.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_NFYB, f)\n",
    "print('NFYB:', NFYB_stat)\n",
    "print('Normalized NFYB:', normal_NFYB_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEAD4.pkl\n",
    "with open('TF_datasets/TEAD4.pkl', 'rb') as f:\n",
    "    TEAD4 = pickle.load(f)\n",
    "normal_TEAD4, TEAD4_stat = normalizer(TEAD4)\n",
    "normal_TEAD4_stat = stat_checker(normal_TEAD4)\n",
    "with open('normal_datasets/TEAD4.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_TEAD4, f)\n",
    "print('TEAD4:', TEAD4_stat)\n",
    "print('Normalized TEAD4:', normal_TEAD4_stat)\n",
    "\n",
    "# POLR2A.pkl\n",
    "with open('TF_datasets/POLR2A.pkl', 'rb') as f:\n",
    "    POLR2A = pickle.load(f)\n",
    "normal_POLR2A, POLR2A_stat = normalizer(POLR2A)\n",
    "normal_POLR2A_stat = stat_checker(normal_POLR2A)\n",
    "with open('normal_datasets/POLR2A.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_POLR2A, f)\n",
    "print('POLR2A:', POLR2A_stat)\n",
    "print('Normalized POLR2A:', normal_POLR2A_stat)\n",
    "\n",
    "# STAT5A.pkl\n",
    "with open('TF_datasets/STAT5A.pkl', 'rb') as f:\n",
    "    STAT5A = pickle.load(f)\n",
    "normal_STAT5A, STAT5A_stat = normalizer(STAT5A)\n",
    "normal_STAT5A_stat = stat_checker(normal_STAT5A)\n",
    "with open('normal_datasets/STAT5A.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_STAT5A, f)\n",
    "print('STAT5A:', STAT5A_stat)\n",
    "print('Normalized STAT5A:', normal_STAT5A_stat)\n",
    "\n",
    "# PRDM1.pkl\n",
    "with open('TF_datasets/PRDM1.pkl', 'rb') as f:\n",
    "    PRDM1 = pickle.load(f)\n",
    "normal_PRDM1, PRDM1_stat = normalizer(PRDM1)\n",
    "normal_PRDM1_stat = stat_checker(normal_PRDM1)\n",
    "with open('normal_datasets/PRDM1.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_PRDM1, f)\n",
    "print('PRDM1:', PRDM1_stat)\n",
    "print('Normalized PRDM1:', normal_PRDM1_stat)\n",
    "\n",
    "# TBP.pkl\n",
    "with open('TF_datasets/TBP.pkl', 'rb') as f:\n",
    "    TBP = pickle.load(f)\n",
    "normal_TBP, TBP_stat = normalizer(TBP)\n",
    "normal_TBP_stat = stat_checker(normal_TBP)\n",
    "with open('normal_datasets/TBP.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_TBP, f)\n",
    "print('TBP:', TBP_stat)\n",
    "print('Normalized TBP:', normal_TBP_stat)\n",
    "\n",
    "# EBF1.pkl\n",
    "with open('TF_datasets/EBF1.pkl', 'rb') as f:\n",
    "    EBF1 = pickle.load(f)\n",
    "normal_EBF1, EBF1_stat = normalizer(EBF1)\n",
    "normal_EBF1_stat = stat_checker(normal_EBF1)\n",
    "with open('normal_datasets/EBF1.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_EBF1, f)\n",
    "print('EBF1:', EBF1_stat)\n",
    "print('Normalized EBF1:', normal_EBF1_stat)\n",
    "\n",
    "# TCF12.pkl\n",
    "with open('TF_datasets/TCF12.pkl', 'rb') as f:\n",
    "    TCF12 = pickle.load(f)\n",
    "normal_TCF12, TCF12_stat = normalizer(TCF12)\n",
    "normal_TCF12_stat = stat_checker(normal_TCF12)\n",
    "with open('normal_datasets/TCF12.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_TCF12, f)\n",
    "print('TCF12:', TCF12_stat)\n",
    "print('Normalized TCF12:', normal_TCF12_stat)\n",
    "\n",
    "# CEBPB.pkl\n",
    "with open('TF_datasets/CEBPB.pkl', 'rb') as f:\n",
    "    CEBPB = pickle.load(f)\n",
    "normal_CEBPB, CEBPB_stat = normalizer(CEBPB)\n",
    "normal_CEBPB_stat = stat_checker(normal_CEBPB)\n",
    "with open('normal_datasets/CEBPB.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_CEBPB, f)\n",
    "print('CEBPB:', CEBPB_stat)\n",
    "print('Normalized CEBPB:', normal_CEBPB_stat)\n",
    "\n",
    "# BRCA1.pkl\n",
    "with open('TF_datasets/BRCA1.pkl', 'rb') as f:\n",
    "    BRCA1 = pickle.load(f)\n",
    "normal_BRCA1, BRCA1_stat = normalizer(BRCA1)\n",
    "normal_BRCA1_stat = stat_checker(normal_BRCA1)\n",
    "with open('normal_datasets/BRCA1.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_BRCA1, f)\n",
    "print('BRCA1:', BRCA1_stat)\n",
    "print('Normalized BRCA1:', normal_BRCA1_stat)\n",
    "\n",
    "# TAF7.pkl\n",
    "with open('TF_datasets/TAF7.pkl', 'rb') as f:\n",
    "    TAF7 = pickle.load(f)\n",
    "normal_TAF7, TAF7_stat = normalizer(TAF7)\n",
    "normal_TAF7_stat = stat_checker(normal_TAF7)\n",
    "with open('normal_datasets/TAF7.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_TAF7, f)\n",
    "print('TAF7:', TAF7_stat)\n",
    "print('Normalized TAF7:', normal_TAF7_stat)\n",
    "\n",
    "# FOSL1.pkl\n",
    "with open('TF_datasets/FOSL1.pkl', 'rb') as f:\n",
    "    FOSL1 = pickle.load(f)\n",
    "normal_FOSL1, FOSL1_stat = normalizer(FOSL1)\n",
    "normal_FOSL1_stat = stat_checker(normal_FOSL1)\n",
    "with open('normal_datasets/FOSL1.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_FOSL1, f)\n",
    "print('FOSL1:', FOSL1_stat)\n",
    "print('Normalized FOSL1:', normal_FOSL1_stat)\n",
    "\n",
    "# RAD21.pkl\n",
    "with open('TF_datasets/RAD21.pkl', 'rb') as f:\n",
    "    RAD21 = pickle.load(f)\n",
    "normal_RAD21, RAD21_stat = normalizer(RAD21)\n",
    "normal_RAD21_stat = stat_checker(normal_RAD21)\n",
    "with open('normal_datasets/RAD21.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_RAD21, f)\n",
    "print('RAD21:', RAD21_stat)\n",
    "print('Normalized RAD21:', normal_RAD21_stat)\n",
    "\n",
    "# HNF4A.pkl\n",
    "with open('TF_datasets/HNF4A.pkl', 'rb') as f:\n",
    "    HNF4A = pickle.load(f)\n",
    "normal_HNF4A, HNF4A_stat = normalizer(HNF4A)\n",
    "normal_HNF4A_stat = stat_checker(normal_HNF4A)\n",
    "with open('normal_datasets/HNF4A.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_HNF4A, f)\n",
    "print('HNF4A:', HNF4A_stat)\n",
    "print('Normalized HNF4A:', normal_HNF4A_stat)\n",
    "\n",
    "# ATF3.pkl\n",
    "with open('TF_datasets/ATF3.pkl', 'rb') as f:\n",
    "    ATF3 = pickle.load(f)\n",
    "normal_ATF3, ATF3_stat = normalizer(ATF3)\n",
    "normal_ATF3_stat = stat_checker(normal_ATF3)\n",
    "with open('normal_datasets/ATF3.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_ATF3, f)\n",
    "print('ATF3:', ATF3_stat)\n",
    "print('Normalized ATF3:', normal_ATF3_stat)\n",
    "\n",
    "# MAX.pkl\n",
    "with open('TF_datasets/MAX.pkl', 'rb') as f:\n",
    "    MAX = pickle.load(f)\n",
    "normal_MAX, MAX_stat = normalizer(MAX)\n",
    "normal_MAX_stat = stat_checker(normal_MAX)\n",
    "with open('normal_datasets/MAX.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_MAX, f)\n",
    "print('MAX:', MAX_stat)\n",
    "print('Normalized MAX:', normal_MAX_stat)\n",
    "\n",
    "# NR2F2.pkl\n",
    "with open('TF_datasets/NR2F2.pkl', 'rb') as f:\n",
    "    NR2F2 = pickle.load(f)\n",
    "normal_NR2F2, NR2F2_stat = normalizer(NR2F2)\n",
    "normal_NR2F2_stat = stat_checker(normal_NR2F2)\n",
    "with open('normal_datasets/NR2F2.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_NR2F2, f)\n",
    "print('NR2F2:', NR2F2_stat)\n",
    "print('Normalized NR2F2:', normal_NR2F2_stat)\n",
    "\n",
    "# GATA3.pkl\n",
    "with open('TF_datasets/GATA3.pkl', 'rb') as f:\n",
    "    GATA3 = pickle.load(f)\n",
    "normal_GATA3, GATA3_stat = normalizer(GATA3)\n",
    "normal_GATA3_stat = stat_checker(normal_GATA3)\n",
    "with open('normal_datasets/GATA3.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_GATA3, f)\n",
    "print('GATA3:', GATA3_stat)\n",
    "print('Normalized GATA3:', normal_GATA3_stat)\n",
    "\n",
    "# MAFK.pkl\n",
    "with open('TF_datasets/MAFK.pkl', 'rb') as f:\n",
    "    MAFK = pickle.load(f)\n",
    "normal_MAFK, MAFK_stat = normalizer(MAFK)\n",
    "normal_MAFK_stat = stat_checker(normal_MAFK)\n",
    "with open('normal_datasets/MAFK.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_MAFK, f)\n",
    "print('MAFK:', MAFK_stat)\n",
    "print('Normalized MAFK:', normal_MAFK_stat)\n",
    "\n",
    "# MEF2A.pkl\n",
    "with open('TF_datasets/MEF2A.pkl', 'rb') as f:\n",
    "    MEF2A = pickle.load(f)\n",
    "normal_MEF2A, MEF2A_stat = normalizer(MEF2A)\n",
    "normal_MEF2A_stat = stat_checker(normal_MEF2A)\n",
    "with open('normal_datasets/MEF2A.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_MEF2A, f)\n",
    "print('MEF2A:', MEF2A_stat)\n",
    "print('Normalized MEF2A:', normal_MEF2A_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BHLHE40: {'coord': {'mean': 0.19281423450744678, 'std': 0.039394376513537194}, 'coord_sq': {'mean': 0.15070829952832807, 'std': 0.040145930450081066}, 'flip': {'mean': 0.07528967358301522, 'std': 0.018784864574119674}}\n",
      "Normalized BHLHE40: {'coord': {'mean': -5.707157832214569e-15, 'std': 0.9999999999999993}, 'coord_sq': {'mean': 9.27596188496354e-15, 'std': 0.999999999999998}, 'flip': {'mean': 5.383677678710904e-15, 'std': 0.9999999999999981}}\n",
      "BCL3: {'coord': {'mean': 0.19340744673699412, 'std': 0.03921604632171243}, 'coord_sq': {'mean': 0.1513644954855402, 'std': 0.03994003768955408}, 'flip': {'mean': 0.07558836321647748, 'std': 0.018681151399392085}}\n",
      "Normalized BCL3: {'coord': {'mean': -3.534576043044305e-16, 'std': 0.9999999999999998}, 'coord_sq': {'mean': -2.8879755984174094e-15, 'std': 1.0000000000000016}, 'flip': {'mean': -1.2662258586275735e-16, 'std': 1.0}}\n",
      "SMC3: {'coord': {'mean': 0.1937081286940591, 'std': 0.03933852064524223}, 'coord_sq': {'mean': 0.15176962795053306, 'std': 0.04012777876940042}, 'flip': {'mean': 0.0757619684846581, 'std': 0.018753187297499183}}\n",
      "Normalized SMC3: {'coord': {'mean': 7.0868013619255965e-15, 'std': 1.0000000000000042}, 'coord_sq': {'mean': -8.565610662065143e-15, 'std': 0.9999999999999974}, 'flip': {'mean': -6.159418138571714e-15, 'std': 0.9999999999999998}}\n",
      "FOXA1: {'coord': {'mean': 0.19418523885076655, 'std': 0.03926820576129315}, 'coord_sq': {'mean': 0.15231357313631885, 'std': 0.04003883563935841}, 'flip': {'mean': 0.07600778008134555, 'std': 0.018712229868280403}}\n",
      "Normalized FOXA1: {'coord': {'mean': -1.983215180092878e-14, 'std': 1.000000000000002}, 'coord_sq': {'mean': 2.403975939071293e-15, 'std': 0.9999999999999998}, 'flip': {'mean': 5.6835224491680595e-15, 'std': 1.0000000000000009}}\n",
      "YY1: {'coord': {'mean': 0.19320776192669126, 'std': 0.039337406306083324}, 'coord_sq': {'mean': 0.1511755566742471, 'std': 0.04008474122399323}, 'flip': {'mean': 0.07549998967178194, 'std': 0.01874799763912915}}\n",
      "Normalized YY1: {'coord': {'mean': -4.1827893474995855e-14, 'std': 0.9999999999999954}, 'coord_sq': {'mean': -2.4320795827859667e-14, 'std': 0.9999999999999987}, 'flip': {'mean': -7.012438131794115e-15, 'std': 0.9999999999999974}}\n"
     ]
    }
   ],
   "source": [
    "# BHLHE40.pkl\n",
    "with open('TF_datasets/BHLHE40.pkl', 'rb') as f:\n",
    "    BHLHE40 = pickle.load(f)\n",
    "normal_BHLHE40, BHLHE40_stat = normalizer(BHLHE40)\n",
    "normal_BHLHE40_stat = stat_checker(normal_BHLHE40)\n",
    "with open('normal_datasets/BHLHE40.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_BHLHE40, f)\n",
    "print('BHLHE40:', BHLHE40_stat)\n",
    "print('Normalized BHLHE40:', normal_BHLHE40_stat)\n",
    "\n",
    "# BCL3.pkl\n",
    "with open('TF_datasets/BCL3.pkl', 'rb') as f:\n",
    "    BCL3 = pickle.load(f)\n",
    "normal_BCL3, BCL3_stat = normalizer(BCL3)\n",
    "normal_BCL3_stat = stat_checker(normal_BCL3)\n",
    "with open('normal_datasets/BCL3.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_BCL3, f)\n",
    "print('BCL3:', BCL3_stat)\n",
    "print('Normalized BCL3:', normal_BCL3_stat)\n",
    "\n",
    "# SMC3.pkl\n",
    "with open('TF_datasets/SMC3.pkl', 'rb') as f:\n",
    "    SMC3 = pickle.load(f)\n",
    "normal_SMC3, SMC3_stat = normalizer(SMC3)\n",
    "normal_SMC3_stat = stat_checker(normal_SMC3)\n",
    "with open('normal_datasets/SMC3.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_SMC3, f)\n",
    "print('SMC3:', SMC3_stat)\n",
    "print('Normalized SMC3:', normal_SMC3_stat)\n",
    "\n",
    "# FOXA1.pkl\n",
    "with open('TF_datasets/FOXA1.pkl', 'rb') as f:\n",
    "    FOXA1 = pickle.load(f)\n",
    "normal_FOXA1, FOXA1_stat = normalizer(FOXA1)\n",
    "normal_FOXA1_stat = stat_checker(normal_FOXA1)\n",
    "with open('normal_datasets/FOXA1.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_FOXA1, f)\n",
    "print('FOXA1:', FOXA1_stat)\n",
    "print('Normalized FOXA1:', normal_FOXA1_stat)\n",
    "\n",
    "# YY1.pkl\n",
    "with open('TF_datasets/YY1.pkl', 'rb') as f:\n",
    "    YY1 = pickle.load(f)\n",
    "normal_YY1, YY1_stat = normalizer(YY1)\n",
    "normal_YY1_stat = stat_checker(normal_YY1)\n",
    "with open('normal_datasets/YY1.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_YY1, f)\n",
    "print('YY1:', YY1_stat)\n",
    "print('Normalized YY1:', normal_YY1_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFs = os.listdir('normal_datasets')\n",
    "len(TFs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
